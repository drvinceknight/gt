{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "### Game Theory - mock individual coursework\n\n**Important** Do not delete the cells containing: \n\n```\n### BEGIN SOLUTION\n\n### END SOLUTION\n```\n\nwrite your solution attempts in those cells.\n\nTo submit this notebook:\n\n- Change the name of the notebook from `main` to: `<student_number>`. For example, if your student number is `c1234567` then change the name of the notebook to `c1234567`.\n- **Write all your solution attempts in the correct locations**;\n- **Do not delete** any code that is already in the cells;\n- Save the notebook (`File>Save As`);\n- Follow the instructions given to submit."}, {"cell_type": "markdown", "metadata": {}, "source": "#### Question 1\n\nFor each of the following pairs of matrices, for the corresponding normal form game use [support enumeration](https://nashpy.readthedocs.io/en/stable/how-to/solve-with-support-enumeration.html) to output all Nash equilibria as a list.\n\na. \\\\(\n    A = \\begin{pmatrix}1 & 2 \\\\ 2 & 1\\end{pmatrix}\n    \\qquad\n    B = \\begin{pmatrix}3 & 2 \\\\ 2 & 5\\end{pmatrix}\n    \\\\)\n\nAvailable marks: 2"}, {"cell_type": "code", "execution_count": 1, "metadata": {"tags": ["answer:q1-a"]}, "outputs": [{"data": {"text/plain": "[(array([0.75, 0.25]), array([0.5, 0.5]))]"}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": "import nashpy as nash\nimport numpy as np\n\n### BEGIN SOLUTION\nA = np.array([[1, 2], [2, 1]])\nB = np.array([[3, 2], [2, 5]])\ngame = nash.Game(A, B)\nlist(game.support_enumeration())\n### END SOLUTION"}, {"cell_type": "markdown", "metadata": {}, "source": "b. a. \\\\(\n    A = \\begin{pmatrix}-1 & 2 & 3\\\\ 4 & -2 & 1 \\\\ 5 & -1 & 2\\end{pmatrix}\n    \\qquad\n    B = -A\n    \\\\)\n\n_Available marks: 2_"}, {"cell_type": "code", "execution_count": 3, "metadata": {"tags": ["answer:q1-b"]}, "outputs": [{"data": {"text/plain": "[(array([0.66666667, 0.        , 0.33333333]),\n  array([0.33333333, 0.66666667, 0.        ]))]"}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": "### BEGIN SOLUTION\nA = np.array([[-1, 2, 3], [4, -2, 1], [5, -1, 2]])\ngame = nash.Game(A)\nlist(game.support_enumeration())\n### END SOLUTION"}, {"cell_type": "markdown", "metadata": {}, "source": "c. a. \\\\(\n    A = \\begin{pmatrix}-1 & 2 & 3\\\\ 4 & -2 & 1\\end{pmatrix}\n    \\qquad\n    B = \\begin{pmatrix}-2 & 4 & 3\\\\ 4 & -3 & 1\\end{pmatrix}\n    \\\\)\n\n_Available marks: 2_"}, {"cell_type": "code", "execution_count": 5, "metadata": {"tags": ["answer:q1-c"]}, "outputs": [{"data": {"text/plain": "[(array([1., 0.]), array([0., 1., 0.])),\n (array([0., 1.]), array([1., 0., 0.])),\n (array([0.375, 0.625]), array([0.28571429, 0.        , 0.71428571]))]"}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": "### BEGIN SOLUTION\nA = np.array([[-1, 2, 3], [4, -2, 1]])\nB = np.array([[-2, 4, 3], [4, -3, 1]])\ngame = nash.Game(A, B)\nlist(game.support_enumeration())\n### END SOLUTION"}, {"cell_type": "markdown", "metadata": {}, "source": "### Question 2\n\n\na. Create a variable `A` which has value the [payoff matrix](https://axelrod.readthedocs.io/en/stable/how-to/access_tournament_results.html#payoff-matrix) for a prisoners dilemma tournament with 200 turns between the players in `players`\n\n_Available marks: 5_"}, {"cell_type": "code", "execution_count": 7, "metadata": {"tags": ["answer:q2-a"]}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "Playing matches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 21/21 [00:00<00:00, 70.14it/s]\nAnalysing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 25/25 [00:00<00:00, 118.89it/s]\n"}], "source": "import axelrod as axl\n\nplayers = (\n    axl.AntiTitForTat(),\n    axl.APavlov2011(),\n    axl.EvolvedANN5(),\n    axl.Winner21(),\n    axl.WinStayLoseShift(),\n    axl.TitForTat()\n)\n\n### BEGIN SOLUTION\ntournament = axl.Tournament(players=players, turns=200)\nresults = tournament.play()\nA = results.payoff_matrix\n### END SOLUTION"}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"data": {"text/plain": "[[2.0, 1.5950000000000002, 0.07000000000000002, 1.8, 3.0099999999999993, 2.25],\n [3.145, 3.0, 3.0, 1.01, 3.0, 3.0],\n [4.92, 3.0, 3.0, 2.9549999999999996, 3.0, 3.0],\n [2.8, 1.035, 3.005, 2.9900000000000007, 2.995, 1.035],\n [1.3350000000000002, 3.0, 3.0, 0.5199999999999999, 3.0, 3.0],\n [2.25, 3.0, 3.0, 1.01, 3.0, 3.0]]"}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": "A"}, {"cell_type": "markdown", "metadata": {}, "source": "b. Using `A`, output a list containing all the Nash equilibria for the associated symmetric 2 player game.\n\n_Available marks: 3_"}, {"cell_type": "code", "execution_count": 10, "metadata": {"tags": ["answer:q2-b"]}, "outputs": [{"data": {"text/plain": "[(array([0., 1., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0.])),\n (array([0., 1., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1.])),\n (array([0., 0., 0., 1., 0., 0.]), array([0., 0., 0., 1., 0., 0.])),\n (array([0., 0., 0., 0., 0., 1.]), array([0., 1., 0., 0., 0., 0.])),\n (array([0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 1.]))]"}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": "### BEGIN SOLUTION\nA = np.array(A)\ngame = nash.Game(A, A.T)\nlist(game.support_enumeration())\n### END SOLUTION"}, {"cell_type": "markdown", "metadata": {}, "source": "### Question 3\n\nConsider the repeated game over two stages $T = 2$ with the following matrices giving the stage game:\n\n$$\nA = \\begin{pmatrix}\n        2 & -2 \\\\\n        -2 & 4\n    \\end{pmatrix}\n\\qquad\nB = \\begin{pmatrix}\n        -3 & 2 \\\\\n        1 & -2\n    \\end{pmatrix}\n$$\n\na. By restricting the strategies available to each player to the assumption that they only consider/know what they did in the first term, using the convention that the tuple `(0, 0)` represents the strategy of playing the first action twice and `(1, 0)` represents the strategy of playing the second strategy and then the first. Create a variable `strategy_space` which is a tuple containing all strategies of the repeated game.\n\n_Available marks: 10_"}, {"cell_type": "code", "execution_count": 12, "metadata": {"tags": ["answer:q3-a"]}, "outputs": [], "source": "### BEGIN SOLUTION\nstrategy_space = (\n    (0, 0),\n    (0, 1),\n    (1, 0),\n    (1, 1),\n)\n### END SOLUTION\n\nassert len(strategy_space) == 4, \"The `strategy_space` value should have length 4\""}, {"cell_type": "markdown", "metadata": {}, "source": "b. Create two variables `A_star` and `B_star` that have values the payoff matrices of normal form game that represents the repeated game.\n\n_Available marks: 4_"}, {"cell_type": "code", "execution_count": 14, "metadata": {"tags": ["answer:q3-b"]}, "outputs": [], "source": "### BEGIN SOLUTION\n# Hard coding A_star and B_star directly is acceptable.\nA = [[2, -2], [-2, 4]]\nB = [[-3, 2], [1, -2]]\nA_star = [\n    [\n        A[row[0]][col[0]] + A[row[1]][col[1]]\n        for col in strategy_space\n    ] for row in strategy_space\n]\nB_star = [\n    [\n        B[row[0]][col[0]] + B[row[1]][col[1]]\n        for col in strategy_space\n    ] for row in strategy_space\n]\n### END SOLUTION"}, {"cell_type": "markdown", "metadata": {}, "source": "c. For the corresponding normal form game use support enumeration to output all Nash equilibria as a list.\n\n_available marks: 2_"}, {"cell_type": "code", "execution_count": 17, "metadata": {"tags": ["answer:q3-c"]}, "outputs": [{"data": {"text/plain": "[(array([0.375, 0.   , 0.   , 0.625]), array([0.6, 0. , 0. , 0.4]))]"}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}], "source": "### BEGIN SOLUTION\ngame = nash.Game(A_star, B_star)\nlist(game.support_enumeration())\n### END SOLUTION"}, {"cell_type": "markdown", "metadata": {}, "source": "### Question 4\n\nFor [matching pennies](https://vknight.org/gt/chapters/01/#Matching-pennies) create a variable `equilibria` with value a list with all Nash equilibria that can be obtained using all possible initial dropped labels of the [Lemke-Howson algorithm](https://nashpy.readthedocs.io/en/stable/text-book/lemke-howson.html). (**Note** the Lemke-Howson algorithm is not covered in the course).\n\n\n_Available marks: 5_"}, {"cell_type": "code", "execution_count": 19, "metadata": {"tags": ["answer:q4"]}, "outputs": [], "source": "### BEGIN SOLUTION\nA = [[1, -1], [-1, 1]]\ngame = nash.Game(A)\nequilibria = list(game.lemke_howson_enumeration())\n### END SOLUTION"}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.3"}}, "nbformat": 4, "nbformat_minor": 4}